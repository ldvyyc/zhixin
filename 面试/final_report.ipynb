{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 260\u001b[0m\n\u001b[1;32m    258\u001b[0m val_percent \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.15\u001b[39m\n\u001b[1;32m    259\u001b[0m test_percent \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.15\u001b[39m\n\u001b[0;32m--> 260\u001b[0m Y_uni, r2_uni \u001b[38;5;241m=\u001b[39m \u001b[43mrun_univariate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_percent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_percent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_percent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m Y_multi, r2_multi \u001b[38;5;241m=\u001b[39m run_multivariate(data, timesteps, hl, lr, batch_size, num_epochs, train_percent, val_percent, test_percent)\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28mprint\u001b[39m(Y_uni\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[0;32mIn[2], line 209\u001b[0m, in \u001b[0;36mrun_univariate\u001b[0;34m(df, timesteps, hl, lr, batch_size, num_epochs, train_percent, val_percent, test_percent)\u001b[0m\n\u001b[1;32m    207\u001b[0m sc_uni \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n\u001b[1;32m    208\u001b[0m train, val, test, all_data \u001b[38;5;241m=\u001b[39m transform_data(sc_uni, series2, train_data, val_data, test_data)\n\u001b[0;32m--> 209\u001b[0m model_uni,train_error,val_error \u001b[38;5;241m=\u001b[39m \u001b[43mfit_model_univariate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhl\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m r2_uni \u001b[38;5;241m=\u001b[39m evaluate_model_univariate(model_uni, test, timesteps)\n\u001b[1;32m    212\u001b[0m Y_hat \u001b[38;5;241m=\u001b[39m generate_output_univariate(model_uni, all_data,timesteps, sc_uni)\n",
      "Cell \u001b[0;32mIn[2], line 70\u001b[0m, in \u001b[0;36mfit_model_univariate\u001b[0;34m(train, val, timesteps, hl, lr, batch, epochs)\u001b[0m\n\u001b[1;32m     67\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer \u001b[38;5;241m=\u001b[39m optimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mlr), loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Training the data\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# model.reset_states()\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m], history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:118\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:323\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    322\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 323\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(\n\u001b[1;32m    325\u001b[0m         step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    326\u001b[0m     )\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# pip install numpy pandas matplotlib keras scikit-learn tensorflow\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "import warnings\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Setting up an early stop\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=40,  verbose=0, mode='min')\n",
    "callbacks_list = [earlystop]\n",
    "\n",
    "def data_preprocess(path):\n",
    "    '''\n",
    "    read data from path, and preprocess it\n",
    "    calculate stock price supposing price is 1 at the beginning\n",
    "    '''\n",
    "    df = pd.read_csv(path, header=None)\n",
    "    df.fillna(method=\"ffill\", inplace=True)\n",
    "    # rename columns\n",
    "    df.columns = ['label', 'open', 'high', 'low', 'close']\n",
    "    # calculate price from return\n",
    "    df['close_price'] = (1+df['close']).cumprod()\n",
    "    df['high_price'] = (1+df['high'])*df['close_price'].shift(1)\n",
    "    df['low_price'] = (1+df['low'])*df['close_price'].shift(1)\n",
    "    df['open_price'] = (1+df['open'])*df['close_price'].shift(1)\n",
    "    df.fillna(1, inplace=True)\n",
    "    df['label2'] = df['close_price'].shift(-1)\n",
    "    # ffill for label2\n",
    "    df.fillna(method=\"ffill\", inplace=True)\n",
    "    return df\n",
    "\n",
    "#Build and train the model\n",
    "def fit_model_univariate(train,val,timesteps,hl,lr,batch,epochs):\n",
    "    '''\n",
    "    The first method, Univariate LSTM, only use close price as input\n",
    "    '''\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    X_val = []\n",
    "    Y_val = []\n",
    "    # Loop for training data\n",
    "    for i in range(timesteps,train.shape[0]):\n",
    "        X_train.append(train[i-timesteps:i])\n",
    "        Y_train.append(train[i])\n",
    "    X_train,Y_train = np.array(X_train),np.array(Y_train)\n",
    "  \n",
    "    # Loop for val data\n",
    "    for i in range(timesteps,val.shape[0]):\n",
    "        X_val.append(val[i-timesteps:i])\n",
    "        Y_val.append(val[i])\n",
    "    X_val,Y_val = np.array(X_val),np.array(Y_val)\n",
    "  \n",
    "    # Adding Layers to the model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(1,input_shape = (X_train.shape[1],1),return_sequences = True, activation = 'relu'))\n",
    "    for i in range(len(hl)-1):        \n",
    "        model.add(LSTM(hl[i],activation = 'relu',return_sequences = True))\n",
    "    model.add(LSTM(hl[-1],activation = 'relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer = optimizers.Adam(learning_rate=lr), loss = 'mean_squared_error')\n",
    "  \n",
    "    # Training the data\n",
    "    history = model.fit(X_train,Y_train,epochs = epochs, batch_size = batch, validation_data = (X_val, Y_val),\n",
    "                        verbose = 0, shuffle = False, callbacks=callbacks_list)\n",
    "    # model.reset_states()\n",
    "    return model, history.history['loss'], history.history['val_loss']\n",
    "\n",
    "#Build and train the model\n",
    "def fit_model_multivariate(train,val,timesteps,hl,lr,batch,epochs):\n",
    "    '''\n",
    "    The second method, Multivariate LSTM, use all features as input\n",
    "    '''\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    X_val = []\n",
    "    Y_val = []\n",
    "  \n",
    "    # Loop for training data\n",
    "    for i in range(timesteps,train.shape[0]+1):\n",
    "        X_train.append(train[i-timesteps:i, 0:4])\n",
    "        Y_train.append(train[i-1][4])\n",
    "    X_train,Y_train = np.array(X_train),np.array(Y_train)\n",
    "  \n",
    "    # Loop for val data\n",
    "    for i in range(timesteps,val.shape[0]+1):\n",
    "        X_val.append(val[i-timesteps:i,0:4])\n",
    "        Y_val.append(val[i-1][4])\n",
    "    X_val,Y_val = np.array(X_val),np.array(Y_val)\n",
    "    \n",
    "    # Adding Layers to the model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(X_train.shape[2],input_shape = (X_train.shape[1],X_train.shape[2]),return_sequences = True,\n",
    "                   activation = 'relu'))\n",
    "    for i in range(len(hl)-1):        \n",
    "        model.add(LSTM(hl[i],activation = 'relu',return_sequences = True))\n",
    "    model.add(LSTM(hl[-1],activation = 'relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer = optimizers.Adam(learning_rate = lr), loss = 'mean_squared_error')\n",
    "  \n",
    "    # Training the data\n",
    "    history = model.fit(X_train,Y_train,epochs = epochs,batch_size = batch,validation_data = (X_val, Y_val),verbose = 0,\n",
    "                        shuffle = False, callbacks=callbacks_list)\n",
    "    # model.reset_states()\n",
    "    return model, history.history['loss'], history.history['val_loss']\n",
    "\n",
    "\n",
    "# Evaluating the model\n",
    "def evaluate_model_univariate(model,test,timesteps):\n",
    "    X_test = []\n",
    "    Y_test = []\n",
    "\n",
    "    # Loop for testing data\n",
    "    for i in range(timesteps,test.shape[0]):\n",
    "        X_test.append(test[i-timesteps:i])\n",
    "        Y_test.append(test[i])\n",
    "    X_test,Y_test = np.array(X_test),np.array(Y_test)\n",
    "  \n",
    "    Y_hat = model.predict(X_test, verbose=0)\n",
    "    r2 = r2_score(Y_test,Y_hat)\n",
    "    return r2\n",
    "\n",
    "def evaluate_model_multivariate(model,test,timesteps):\n",
    "    X_test = []\n",
    "    Y_test = []\n",
    "\n",
    "    # Loop for testing data\n",
    "    for i in range(timesteps,test.shape[0]+1):\n",
    "        X_test.append(test[i-timesteps:i, 0:4])\n",
    "        Y_test.append(test[i-1][4])\n",
    "    X_test,Y_test = np.array(X_test),np.array(Y_test)\n",
    "  \n",
    "    Y_hat = model.predict(X_test, verbose=0)\n",
    "    r2 = r2_score(Y_test,Y_hat)\n",
    "    return r2\n",
    "  \n",
    "\n",
    "\n",
    "def generate_output_univariate(model, all_data, timesteps, sc):\n",
    "    X_all = []\n",
    "    Y_all = []\n",
    "    for i in range(timesteps,all_data.shape[0]):\n",
    "        X_all.append(all_data[i-timesteps:i])\n",
    "        Y_all.append(all_data[i])\n",
    "    X_all,Y_all = np.array(X_all),np.array(Y_all)\n",
    "    Y_hat = model.predict(X_all, verbose=0)\n",
    "    Y_hat = np.array(Y_hat)\n",
    "    Y_hat = sc.inverse_transform(Y_hat)\n",
    "    Y_all = sc.inverse_transform(Y_all)\n",
    "    c = np.concatenate((Y_all[:timesteps].reshape(-1), Y_hat.reshape(-1)))\n",
    "    return c, Y_all\n",
    "\n",
    "# Evaluating the model\n",
    "def generate_output_multivariate(model,all_data,timesteps, sc):\n",
    "    X_test = []\n",
    "    Y_test = []\n",
    "\n",
    "    # Loop for testing data\n",
    "    for i in range(timesteps,all_data.shape[0]+1):\n",
    "        X_test.append(all_data[i-timesteps:i, 0:4])\n",
    "        Y_test.append(all_data[i-1][4])\n",
    "    X_test,Y_test = np.array(X_test),np.array(Y_test)\n",
    "\n",
    "\n",
    "    Y_hat = model.predict(X_test, verbose=0)\n",
    "    # create a new array, first timesteps is all_data[:timesteps, 4], then Y_hat\n",
    "    c = np.concatenate((all_data[:timesteps-1, 3], Y_hat.reshape(-1)))\n",
    "\n",
    "    Y_hat_tmp= np.zeros_like(all_data)\n",
    "    Y_hat_tmp[:len(all_data),4] = c.reshape(-1)\n",
    "    Y_hat_tmp = sc.inverse_transform(Y_hat_tmp)[:,4]\n",
    "\n",
    "    return Y_hat_tmp\n",
    "  \n",
    "\n",
    "def split_data(series, train_percent, val_percent, test_percent):\n",
    "    '''\n",
    "    Split data into train, val, test\n",
    "    '''\n",
    "    train_data = series[:int(train_percent*len(series))]\n",
    "    val_data = series[int(train_percent*len(series)):int((train_percent+val_percent)*len(series))]\n",
    "    test_data = series[int((train_percent+val_percent)*len(series)):]\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "def transform_data(scalar, all, train, val, test):\n",
    "    '''\n",
    "    Normalize data\n",
    "    '''\n",
    "    train = scalar.fit_transform(train)\n",
    "    val = scalar.transform(val)\n",
    "    test = scalar.transform(test)\n",
    "    all = scalar.transform(all)\n",
    "    return train, val, test, all\n",
    "\n",
    "def run_univariate(df, timesteps, hl, lr, batch_size, num_epochs, train_percent, val_percent, test_percent):\n",
    "    # Extracting the series\n",
    "    series = df['close_price']\n",
    "    series2 = series.values.reshape(-1,1)\n",
    "    train_data, val_data, test_data = split_data(series2, train_percent, val_percent, test_percent)\n",
    "    # Normalization\n",
    "    sc_uni = MinMaxScaler()\n",
    "    train, val, test, all_data = transform_data(sc_uni, series2, train_data, val_data, test_data)\n",
    "    model_uni,train_error,val_error = fit_model_univariate(train,val,timesteps,hl,lr,batch_size,num_epochs)\n",
    "    \n",
    "    r2_uni = evaluate_model_univariate(model_uni, test, timesteps)\n",
    "    Y_hat = generate_output_univariate(model_uni, all_data,timesteps, sc_uni)\n",
    "    del model_uni\n",
    "    return Y_hat, r2_uni\n",
    "\n",
    "def run_multivariate(df, timesteps, hl, lr, batch_size, num_epochs, train_percent, val_percent, test_percent):\n",
    "    # Extracting the series\n",
    "    series = df[['open_price', 'high_price', 'low_price', 'close_price', 'label2']]\n",
    "    series2 = series.values\n",
    "    # split data for training\n",
    "    train_data, val_data, test_data = split_data(series2, train_percent, val_percent, test_percent)\n",
    "    # Normalization\n",
    "    sc_multi = MinMaxScaler()\n",
    "    train, val, test, all_data = transform_data(sc_multi, series2, train_data, val_data, test_data)\n",
    "    model,train_error,val_error = fit_model_multivariate(train,val,timesteps,hl,lr,batch_size,num_epochs)\n",
    "    r2_multi = evaluate_model_multivariate(model, test, timesteps)\n",
    "    Y_hat = generate_output_multivariate(model, all_data,timesteps, sc_multi)\n",
    "    del model\n",
    "    return Y_hat, r2_multi\n",
    "\n",
    "def convert_price_to_return(Y_hat):\n",
    "    '''\n",
    "    convert price to return\n",
    "    '''\n",
    "    df2 = pd.DataFrame({'Predicted': Y_hat.flatten()})\n",
    "    df2['predicted_return'] = df2['Predicted'].pct_change()\n",
    "    df2.fillna(0, inplace=True)\n",
    "    return df2\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    # read from args\n",
    "    # if len(sys.argv) != 2:\n",
    "    #     # print(\"Usage: python final1.py <input_file>\")\n",
    "    #     sys.exit(1)\n",
    "    # file_path = sys.argv[1]\n",
    "    file_path = \"dataset-20230501.csv\"\n",
    "    # read data\n",
    "    data = data_preprocess(file_path)\n",
    "    # set hyperparameters\n",
    "    timesteps = 40\n",
    "    hl = [40,35] # hidden layers\n",
    "    lr = 0.0005\n",
    "    batch_size = 64\n",
    "    num_epochs = 150\n",
    "    train_percent = 0.7\n",
    "    val_percent = 0.15\n",
    "    test_percent = 0.15\n",
    "    Y_uni, r2_uni = run_univariate(data, timesteps, hl, lr, batch_size, num_epochs, train_percent, val_percent, test_percent)\n",
    "    Y_multi, r2_multi = run_multivariate(data, timesteps, hl, lr, batch_size, num_epochs, train_percent, val_percent, test_percent)\n",
    "    print(Y_uni.shape)\n",
    "    print(Y_multi.shape)\n",
    "    print(r2_uni)\n",
    "    print(r2_multi)\n",
    "    if (r2_multi > r2_uni):\n",
    "        Y = Y_multi\n",
    "    else:\n",
    "        Y = Y_uni\n",
    "    \n",
    "    returns_df = convert_price_to_return(Y)\n",
    "    for i in range(len(returns_df)):\n",
    "        print(i, returns_df['predicted_return'][i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "# from scipy.stats import sharpe_ratio\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.X[idx], dtype=torch.float), torch.tensor(self.y[idx], dtype=torch.float)\n",
    "\n",
    "# # Define Transformer model\n",
    "# class TransformerModel(nn.Module):\n",
    "#     def __init__(self, input_dim, num_heads, num_layers, hidden_dim, embed_dim):\n",
    "#         super(TransformerModel, self).__init__()\n",
    "#         self.input_linear = nn.Linear(input_dim, embed_dim)\n",
    "#         self.encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dim_feedforward=hidden_dim)\n",
    "#         self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "#         self.linear = nn.Linear(input_dim, 1)\n",
    "\n",
    "#     def forward(self, src):\n",
    "#         output = self.transformer_encoder(src)\n",
    "#         output = self.linear(output[:, -1, :])\n",
    "#         return output\n",
    "    \n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, num_heads, num_layers):\n",
    "        super().__init__()\n",
    "        self.input_linear = nn.Linear(input_dim, embed_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.output_linear = nn.Linear(embed_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_linear(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = self.output_linear(x)\n",
    "        return x.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Train Size: 796 - R2: -93.4021 - MSE: 0.0047 - Accuracy: 0.5625 - Sharpe Ratio: 9.8560209274292\n",
      "Epoch 2/10 - Train Size: 796 - R2: -19.1252 - MSE: 0.0010 - Accuracy: 0.4250 - Sharpe Ratio: 4.1818389892578125\n",
      "Epoch 3/10 - Train Size: 796 - R2: -30.5048 - MSE: 0.0016 - Accuracy: 0.4250 - Sharpe Ratio: 5.331697463989258\n",
      "Epoch 4/10 - Train Size: 796 - R2: -1.9777 - MSE: 0.0001 - Accuracy: 0.4250 - Sharpe Ratio: 1.214908242225647\n",
      "Epoch 5/10 - Train Size: 796 - R2: -3.0784 - MSE: 0.0002 - Accuracy: 0.5625 - Sharpe Ratio: 1.946038842201233\n",
      "Epoch 6/10 - Train Size: 796 - R2: -14.1024 - MSE: 0.0007 - Accuracy: 0.4250 - Sharpe Ratio: 3.5637850761413574\n",
      "Epoch 7/10 - Train Size: 796 - R2: -0.0299 - MSE: 0.0001 - Accuracy: 0.5625 - Sharpe Ratio: 0.3613438308238983\n",
      "Epoch 8/10 - Train Size: 796 - R2: -6.0520 - MSE: 0.0003 - Accuracy: 0.4250 - Sharpe Ratio: 2.268578052520752\n",
      "Epoch 9/10 - Train Size: 796 - R2: -1.3056 - MSE: 0.0001 - Accuracy: 0.4250 - Sharpe Ratio: 0.9508493542671204\n",
      "Epoch 10/10 - Train Size: 796 - R2: -0.1390 - MSE: 0.0001 - Accuracy: 0.5625 - Sharpe Ratio: 0.561813235282898\n",
      "Epoch 1/10 - Train Size: 876 - R2: -0.1013 - MSE: 0.0002 - Accuracy: 0.5250 - Sharpe Ratio: 0.39353883266448975\n",
      "Epoch 2/10 - Train Size: 876 - R2: -5.0682 - MSE: 0.0010 - Accuracy: 0.4625 - Sharpe Ratio: 2.1726725101470947\n",
      "Epoch 3/10 - Train Size: 876 - R2: -0.3584 - MSE: 0.0002 - Accuracy: 0.4625 - Sharpe Ratio: 0.5199108123779297\n",
      "Epoch 4/10 - Train Size: 876 - R2: -5.8369 - MSE: 0.0011 - Accuracy: 0.4625 - Sharpe Ratio: 2.337794065475464\n",
      "Epoch 5/10 - Train Size: 876 - R2: -1.3752 - MSE: 0.0004 - Accuracy: 0.4625 - Sharpe Ratio: 1.0945490598678589\n",
      "Epoch 6/10 - Train Size: 876 - R2: -0.0020 - MSE: 0.0002 - Accuracy: 0.5250 - Sharpe Ratio: 0.03269871324300766\n",
      "Epoch 7/10 - Train Size: 876 - R2: -1.5106 - MSE: 0.0004 - Accuracy: 0.5250 - Sharpe Ratio: 1.3069573640823364\n",
      "Epoch 8/10 - Train Size: 876 - R2: -0.3067 - MSE: 0.0002 - Accuracy: 0.4625 - Sharpe Ratio: 0.47576063871383667\n",
      "Epoch 9/10 - Train Size: 876 - R2: -0.1826 - MSE: 0.0002 - Accuracy: 0.5250 - Sharpe Ratio: 0.5050528645515442\n",
      "Epoch 10/10 - Train Size: 876 - R2: -0.1671 - MSE: 0.0002 - Accuracy: 0.4625 - Sharpe Ratio: 0.33067142963409424\n",
      "Epoch 1/10 - Train Size: 956 - R2: -0.0911 - MSE: 0.0001 - Accuracy: 0.4125 - Sharpe Ratio: 0.20321941375732422\n",
      "Epoch 2/10 - Train Size: 956 - R2: -0.6032 - MSE: 0.0002 - Accuracy: 0.4125 - Sharpe Ratio: 0.678837239742279\n",
      "Epoch 3/10 - Train Size: 956 - R2: -0.2163 - MSE: 0.0002 - Accuracy: 0.4125 - Sharpe Ratio: 0.3671426475048065\n",
      "Epoch 4/10 - Train Size: 956 - R2: -0.0290 - MSE: 0.0001 - Accuracy: 0.4125 - Sharpe Ratio: 0.07282615453004837\n",
      "Epoch 5/10 - Train Size: 956 - R2: -0.1905 - MSE: 0.0001 - Accuracy: 0.4125 - Sharpe Ratio: 0.33856624364852905\n",
      "Epoch 6/10 - Train Size: 956 - R2: -0.0166 - MSE: 0.0001 - Accuracy: 0.4125 - Sharpe Ratio: 0.030675597488880157\n",
      "Epoch 7/10 - Train Size: 956 - R2: -0.0067 - MSE: 0.0001 - Accuracy: 0.5875 - Sharpe Ratio: 0.015814626589417458\n",
      "Epoch 8/10 - Train Size: 956 - R2: -0.4459 - MSE: 0.0002 - Accuracy: 0.4125 - Sharpe Ratio: 0.5700482130050659\n",
      "Epoch 9/10 - Train Size: 956 - R2: -0.1165 - MSE: 0.0001 - Accuracy: 0.4125 - Sharpe Ratio: 0.2438424825668335\n",
      "Epoch 10/10 - Train Size: 956 - R2: -0.1652 - MSE: 0.0001 - Accuracy: 0.5875 - Sharpe Ratio: 0.5038455724716187\n",
      "Epoch 1/10 - Train Size: 1036 - R2: -0.1674 - MSE: 0.0002 - Accuracy: 0.5625 - Sharpe Ratio: 0.6129041910171509\n",
      "Epoch 2/10 - Train Size: 1036 - R2: -0.0309 - MSE: 0.0002 - Accuracy: 0.5625 - Sharpe Ratio: 0.027550358325242996\n",
      "Epoch 3/10 - Train Size: 1036 - R2: -0.1053 - MSE: 0.0002 - Accuracy: 0.4125 - Sharpe Ratio: 0.12073072791099548\n",
      "Epoch 4/10 - Train Size: 1036 - R2: -0.1075 - MSE: 0.0002 - Accuracy: 0.4125 - Sharpe Ratio: 0.12391026318073273\n",
      "Epoch 5/10 - Train Size: 1036 - R2: -0.4315 - MSE: 0.0003 - Accuracy: 0.4125 - Sharpe Ratio: 0.4529511332511902\n",
      "Epoch 6/10 - Train Size: 1036 - R2: -0.0253 - MSE: 0.0002 - Accuracy: 0.5625 - Sharpe Ratio: 0.045367054641246796\n",
      "Epoch 7/10 - Train Size: 1036 - R2: -0.0003 - MSE: 0.0002 - Accuracy: 0.5625 - Sharpe Ratio: 0.22213110327720642\n",
      "Epoch 8/10 - Train Size: 1036 - R2: -0.4702 - MSE: 0.0003 - Accuracy: 0.4125 - Sharpe Ratio: 0.48193418979644775\n",
      "Epoch 9/10 - Train Size: 1036 - R2: -0.0421 - MSE: 0.0002 - Accuracy: 0.4000 - Sharpe Ratio: 0.0011144786840304732\n",
      "Epoch 10/10 - Train Size: 1036 - R2: -0.3006 - MSE: 0.0003 - Accuracy: 0.4125 - Sharpe Ratio: 0.34430447220802307\n",
      "Epoch 1/10 - Train Size: 1116 - R2: -1.0049 - MSE: 0.0002 - Accuracy: 0.5625 - Sharpe Ratio: 1.1721737384796143\n",
      "Epoch 2/10 - Train Size: 1116 - R2: -0.1502 - MSE: 0.0001 - Accuracy: 0.4125 - Sharpe Ratio: 0.21780666708946228\n",
      "Epoch 3/10 - Train Size: 1116 - R2: -0.3290 - MSE: 0.0001 - Accuracy: 0.5625 - Sharpe Ratio: 0.7433596849441528\n",
      "Epoch 4/10 - Train Size: 1116 - R2: -0.1742 - MSE: 0.0001 - Accuracy: 0.5625 - Sharpe Ratio: 0.5867494940757751\n",
      "Epoch 5/10 - Train Size: 1116 - R2: -0.3913 - MSE: 0.0001 - Accuracy: 0.5625 - Sharpe Ratio: 0.7950592041015625\n",
      "Epoch 6/10 - Train Size: 1116 - R2: -0.1161 - MSE: 0.0001 - Accuracy: 0.5625 - Sharpe Ratio: 0.5106087923049927\n",
      "Epoch 7/10 - Train Size: 1116 - R2: -0.0781 - MSE: 0.0001 - Accuracy: 0.5625 - Sharpe Ratio: 0.4494798481464386\n",
      "Epoch 8/10 - Train Size: 1116 - R2: -0.1623 - MSE: 0.0001 - Accuracy: 0.5625 - Sharpe Ratio: 0.5725448131561279\n",
      "Epoch 9/10 - Train Size: 1116 - R2: -0.0857 - MSE: 0.0001 - Accuracy: 0.5625 - Sharpe Ratio: 0.4623871445655823\n",
      "Epoch 10/10 - Train Size: 1116 - R2: -0.1499 - MSE: 0.0001 - Accuracy: 0.5625 - Sharpe Ratio: 0.556624174118042\n",
      "Epoch 1/10 - Train Size: 1196 - R2: -0.0097 - MSE: 0.0004 - Accuracy: 0.5750 - Sharpe Ratio: 0.14877517521381378\n",
      "Epoch 2/10 - Train Size: 1196 - R2: -0.0334 - MSE: 0.0004 - Accuracy: 0.5750 - Sharpe Ratio: 0.06508763134479523\n",
      "Epoch 3/10 - Train Size: 1196 - R2: -0.0230 - MSE: 0.0004 - Accuracy: 0.5750 - Sharpe Ratio: 0.09631852060556412\n",
      "Epoch 4/10 - Train Size: 1196 - R2: -0.0794 - MSE: 0.0005 - Accuracy: 0.5750 - Sharpe Ratio: 0.5294008851051331\n",
      "Epoch 5/10 - Train Size: 1196 - R2: -0.0543 - MSE: 0.0004 - Accuracy: 0.5750 - Sharpe Ratio: 0.01339514460414648\n",
      "Epoch 6/10 - Train Size: 1196 - R2: -0.1339 - MSE: 0.0005 - Accuracy: 0.4125 - Sharpe Ratio: 0.11929619312286377\n",
      "Epoch 7/10 - Train Size: 1196 - R2: -0.0225 - MSE: 0.0004 - Accuracy: 0.5750 - Sharpe Ratio: 0.09604315459728241\n",
      "Epoch 8/10 - Train Size: 1196 - R2: -0.0644 - MSE: 0.0005 - Accuracy: 0.4125 - Sharpe Ratio: 0.007095724809914827\n",
      "Epoch 9/10 - Train Size: 1196 - R2: -0.0201 - MSE: 0.0004 - Accuracy: 0.5750 - Sharpe Ratio: 0.10486642271280289\n",
      "Epoch 10/10 - Train Size: 1196 - R2: -0.0484 - MSE: 0.0004 - Accuracy: 0.5750 - Sharpe Ratio: 0.02681092545390129\n",
      "Epoch 1/10 - Train Size: 1276 - R2: -0.1497 - MSE: 0.0007 - Accuracy: 0.4875 - Sharpe Ratio: 0.41535285115242004\n",
      "Epoch 2/10 - Train Size: 1276 - R2: -0.3472 - MSE: 0.0009 - Accuracy: 0.4875 - Sharpe Ratio: 0.6174972057342529\n",
      "Epoch 3/10 - Train Size: 1276 - R2: -0.2341 - MSE: 0.0008 - Accuracy: 0.4875 - Sharpe Ratio: 0.5120304822921753\n",
      "Epoch 4/10 - Train Size: 1276 - R2: -0.2784 - MSE: 0.0008 - Accuracy: 0.4875 - Sharpe Ratio: 0.5558214783668518\n",
      "Epoch 5/10 - Train Size: 1276 - R2: -0.1904 - MSE: 0.0008 - Accuracy: 0.4875 - Sharpe Ratio: 0.4645739793777466\n",
      "Epoch 6/10 - Train Size: 1276 - R2: -0.2687 - MSE: 0.0008 - Accuracy: 0.4875 - Sharpe Ratio: 0.5465577840805054\n",
      "Epoch 7/10 - Train Size: 1276 - R2: -0.6227 - MSE: 0.0011 - Accuracy: 0.4875 - Sharpe Ratio: 0.8171126842498779\n",
      "Epoch 8/10 - Train Size: 1276 - R2: -0.2568 - MSE: 0.0008 - Accuracy: 0.4875 - Sharpe Ratio: 0.534846842288971\n",
      "Epoch 9/10 - Train Size: 1276 - R2: -0.1036 - MSE: 0.0007 - Accuracy: 0.4875 - Sharpe Ratio: 0.35001349449157715\n",
      "Epoch 10/10 - Train Size: 1276 - R2: -0.1768 - MSE: 0.0008 - Accuracy: 0.4875 - Sharpe Ratio: 0.44848448038101196\n",
      "Epoch 1/10 - Train Size: 1356 - R2: -0.0057 - MSE: 0.0007 - Accuracy: 0.5125 - Sharpe Ratio: 0.031119486317038536\n",
      "Epoch 2/10 - Train Size: 1356 - R2: -0.0004 - MSE: 0.0007 - Accuracy: 0.5125 - Sharpe Ratio: 0.08621817082166672\n",
      "Epoch 3/10 - Train Size: 1356 - R2: -0.0404 - MSE: 0.0007 - Accuracy: 0.4875 - Sharpe Ratio: 0.09499666839838028\n",
      "Epoch 4/10 - Train Size: 1356 - R2: -0.0012 - MSE: 0.0007 - Accuracy: 0.5125 - Sharpe Ratio: 0.0683562159538269\n",
      "Epoch 5/10 - Train Size: 1356 - R2: -0.0162 - MSE: 0.0007 - Accuracy: 0.4875 - Sharpe Ratio: 0.0219353586435318\n",
      "Epoch 6/10 - Train Size: 1356 - R2: -0.0023 - MSE: 0.0007 - Accuracy: 0.5125 - Sharpe Ratio: 0.05598197877407074\n",
      "Epoch 7/10 - Train Size: 1356 - R2: -0.0157 - MSE: 0.0007 - Accuracy: 0.4875 - Sharpe Ratio: 0.019979938864707947\n",
      "Epoch 8/10 - Train Size: 1356 - R2: -0.0278 - MSE: 0.0007 - Accuracy: 0.4875 - Sharpe Ratio: 0.061295706778764725\n",
      "Epoch 9/10 - Train Size: 1356 - R2: -0.0478 - MSE: 0.0007 - Accuracy: 0.4875 - Sharpe Ratio: 0.11294432729482651\n",
      "Epoch 10/10 - Train Size: 1356 - R2: -0.0255 - MSE: 0.0007 - Accuracy: 0.4875 - Sharpe Ratio: 0.054085131734609604\n",
      "Epoch 1/10 - Train Size: 1436 - R2: -0.0007 - MSE: 0.0006 - Accuracy: 0.5000 - Sharpe Ratio: 0.008823279291391373\n",
      "Epoch 2/10 - Train Size: 1436 - R2: -0.0046 - MSE: 0.0006 - Accuracy: 0.5000 - Sharpe Ratio: 0.08317739516496658\n",
      "Epoch 3/10 - Train Size: 1436 - R2: -0.0402 - MSE: 0.0006 - Accuracy: 0.5000 - Sharpe Ratio: 0.18380673229694366\n",
      "Epoch 4/10 - Train Size: 1436 - R2: -0.0079 - MSE: 0.0006 - Accuracy: 0.5000 - Sharpe Ratio: 0.07265044748783112\n",
      "Epoch 5/10 - Train Size: 1436 - R2: -0.0022 - MSE: 0.0006 - Accuracy: 0.5000 - Sharpe Ratio: 0.03000795841217041\n",
      "Epoch 6/10 - Train Size: 1436 - R2: -0.0101 - MSE: 0.0006 - Accuracy: 0.5000 - Sharpe Ratio: 0.08381420373916626\n",
      "Epoch 7/10 - Train Size: 1436 - R2: -0.0003 - MSE: 0.0006 - Accuracy: 0.5000 - Sharpe Ratio: 0.033558376133441925\n",
      "Epoch 8/10 - Train Size: 1436 - R2: -0.0128 - MSE: 0.0006 - Accuracy: 0.5000 - Sharpe Ratio: 0.0966472253203392\n",
      "Epoch 9/10 - Train Size: 1436 - R2: -0.0051 - MSE: 0.0006 - Accuracy: 0.5000 - Sharpe Ratio: 0.0548601932823658\n",
      "Epoch 10/10 - Train Size: 1436 - R2: -0.0294 - MSE: 0.0006 - Accuracy: 0.5000 - Sharpe Ratio: 0.15487903356552124\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('new.csv')\n",
    "X = df.iloc[:, 1:].values\n",
    "y = df.iloc[:, 0].values\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim = X_train.shape[1]\n",
    "embed_dim = 64  # Ensure this is divisible by num_heads\n",
    "num_heads = 4\n",
    "num_layers = 2\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "model = TransformerModel(input_dim, embed_dim, num_heads, num_layers)\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop with time series cross-validation\n",
    "train_size = int(0.5 * len(X_train))\n",
    "val_size = 80\n",
    "while train_size + val_size <= len(X_train):\n",
    "    train_dataset = TimeSeriesDataset(X_train[:train_size], y_train[:train_size])\n",
    "    val_dataset = TimeSeriesDataset(X_train[train_size:train_size+val_size], y_train[train_size:train_size+val_size])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs.unsqueeze(0)).squeeze()\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_preds = []\n",
    "            val_targets = []\n",
    "            for inputs, targets in val_loader:\n",
    "                outputs = model(inputs.unsqueeze(0)).squeeze()\n",
    "                val_preds.extend(outputs.numpy())\n",
    "                val_targets.extend(targets.numpy())\n",
    "\n",
    "        r2 = r2_score(val_targets, val_preds)\n",
    "        mse = mean_squared_error(val_targets, val_preds)\n",
    "        accuracy = np.mean(np.sign(val_preds) == np.sign(val_targets))\n",
    "        sharp_ratio = np.mean(np.abs(val_preds)) / np.std(val_targets)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{epochs} - Train Size: {train_size} - R2: {r2:.4f} - MSE: {mse:.4f} - Accuracy: {accuracy:.4f} - Sharpe Ratio: {sharp_ratio}')\n",
    "\n",
    "    train_size += val_size\n",
    "\n",
    "# Test the model\n",
    "test_dataset = TimeSeriesDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_preds = []\n",
    "    test_targets = []\n",
    "    for inputs, targets in test_loader:\n",
    "        outputs = model(inputs.unsqueeze(0)).squeeze()\n",
    "        test_preds.extend(outputs.numpy())\n",
    "        test_targets.extend(targets.numpy())\n",
    "\n",
    "r2 = r2_score(test_targets, test_preds)\n",
    "mse = mean_squared_error(test_targets, test_preds)\n",
    "accuracy = np.mean(np.sign(test_preds) == np.sign(test_targets))\n",
    "# try:\n",
    "#     sharp_ratio = sharpe_ratio(test_preds - test_targets)\n",
    "# except:\n",
    "#     sharp_ratio = 'undefined'\n",
    "\n",
    "# print(f'Test Results - R2: {r2:.4f} - MSE: {mse:.4f} - Accuracy:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation Loss: 0.0035988595336675644\n",
      "Epoch 2, Validation Loss: 0.000619834812823683\n",
      "Epoch 3, Validation Loss: 0.0004354062839411199\n",
      "Epoch 4, Validation Loss: 0.00041052736924029887\n",
      "Epoch 5, Validation Loss: 0.00035818127798847854\n",
      "Epoch 6, Validation Loss: 0.0004348757502157241\n",
      "Epoch 7, Validation Loss: 0.00024258042685687542\n",
      "Epoch 8, Validation Loss: 0.0003775167861022055\n",
      "Epoch 9, Validation Loss: 0.0003454034449532628\n",
      "Epoch 10, Validation Loss: 0.000256297760643065\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "# from scipy.stats import sharpe_ratio\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('new.csv')\n",
    "X = df.iloc[:, 1:].values  # Features\n",
    "y = df.iloc[:, 0].values   # Target\n",
    "\n",
    "# Split data\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_val = X[:train_size], X[train_size:]\n",
    "y_train, y_val = y[:train_size], y[train_size:]\n",
    "\n",
    "# Standardize data\n",
    "mean, std = X_train.mean(axis=0), X_train.std(axis=0)\n",
    "X_train = (X_train - mean) / std\n",
    "X_val = (X_val - mean) / std\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor, y_train_tensor = torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val_tensor, y_val_tensor = torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "# Define model\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, num_heads, num_layers):\n",
    "        super().__init__()\n",
    "        self.input_linear = nn.Linear(input_dim, embed_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.output_linear = nn.Linear(embed_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_linear(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = self.output_linear(x)\n",
    "        return x.squeeze(-1)\n",
    "\n",
    "# Adjust these parameters as needed to ensure embed_dim is divisible by num_heads\n",
    "input_dim = X_train.shape[1]\n",
    "embed_dim = 64  # Ensure this is divisible by num_heads\n",
    "num_heads = 4\n",
    "num_layers = 2\n",
    "\n",
    "model = TransformerModel(input_dim, embed_dim, num_heads, num_layers)\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# DataLoaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_val_pred = model(X_val_tensor)\n",
    "        val_loss = loss_fn(y_val_pred, y_val_tensor)\n",
    "\n",
    "    print(f'Epoch {epoch + 1}, Validation Loss: {val_loss.item()}')\n",
    "\n",
    "# Evaluation metrics\n",
    "y_val_pred = y_val_pred.numpy()\n",
    "r2 = r2_score(y_val, y_val_pred)\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "accuracy = np.mean(np.sign(y_val) == np.sign(y_val_pred))\n",
    "# try:\n",
    "#     sharpe = sharpe_ratio(y_val_pred - y_val)\n",
    "# except ZeroDivisionError:\n",
    "#     sharpe = 0.0\n",
    "\n",
    "# print(f'R2: {r2}, MSE: {mse}, Accuracy: {accuracy}, Sharpe Ratio: {sharpe}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
